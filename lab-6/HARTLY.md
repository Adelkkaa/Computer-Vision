Метод Хартли (или метод, основанный на фундаментальной матрице) — это альтернативный подход к стереоректификации, который не требует предварительной калибровки камер. Вместо этого он использует только соответствия между точками на двух изображениях для вычисления фундаментальной матрицы и последующей ректификации.

---

### Основная идея метода Хартли

1. **Нахождение соответствий**: Используем алгоритмы детектирования ключевых точек (например, SIFT) для поиска соответствий между двумя изображениями.
2. **Вычисление фундаментальной матрицы**: На основе найденных соответствий строим фундаментальную матрицу, которая описывает геометрические отношения между двумя изображениями.
3. **Ректификация**: Применяем гомографию к одному из изображений, чтобы выровнять эпиполярные линии.

---

### Код функции `fundamental_matrix_method`

#### Полный код функции:
```python
def fundamental_matrix_method(imgL, imgR):
    sift = cv2.SIFT_create()  # Создаем объект SIFT для детектирования ключевых точек
    kp1, des1 = sift.detectAndCompute(imgL, None)  # Находим ключевые точки и их описатели на левом изображении
    kp2, des2 = sift.detectAndCompute(imgR, None)  # Находим ключевые точки и их описатели на правом изображении

    bf = cv2.BFMatcher()  # Создаем объект BFMatcher для сопоставления описателей
    matches = bf.knnMatch(des1, des2, k=2)  # Находим две лучших соответствия для каждой точки

    good_matches = [m for m, n in matches if m.distance < 0.7 * n.distance]  # Отфильтровываем плохие соответствия

    if len(good_matches) < 8:  # Проверяем, что есть достаточно хороших соответствий
        print("Недостаточно совпадений.")
        return None, None

    src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 2)  # Координаты точек на левом изображении
    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 2)  # Координаты точек на правом изображении

    F, mask = cv2.findFundamentalMat(src_pts, dst_pts, cv2.FM_RANSAC)  # Вычисляем фундаментальную матрицу
    if F is None:  # Проверяем, что фундаментальная матрица успешно вычислена
        print("Ошибка: не удалось вычислить фундаментальную матрицу.")
        return None, None

    H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC)  # Вычисляем гомографию

    rectified_imgL = cv2.warpPerspective(imgL, H, (imgL.shape[1], imgL.shape[0]))  # Применяем гомографию к левому изображению
    rectified_imgR = imgR  # Правому изображению не нужно применять преобразование

    return rectified_imgL, rectified_imgR  # Возвращаем откалиброванные изображения
```

---

### Разбор кода построчно:

#### 1. Детектирование ключевых точек
```python
sift = cv2.SIFT_create()  # Создаем объект SIFT для детектирования ключевых точек
kp1, des1 = sift.detectAndCompute(imgL, None)  # Находим ключевые точки и их описатели на левом изображении
kp2, des2 = sift.detectAndCompute(imgR, None)  # Находим ключевые точки и их описатели на правом изображении
```

- **`cv2.SIFT_create()`**: Создает объект SIFT для обнаружения ключевых точек и их описателей.
- **`detectAndCompute`**:
  - Находит ключевые точки (`kp1`, `kp2`) на обоих изображениях.
  - Вычисляет описатели (`des1`, `des2`) для каждой точки.

---

#### 2. Сопоставление точек
```python
bf = cv2.BFMatcher()  # Создаем объект BFMatcher для сопоставления описателей
matches = bf.knnMatch(des1, des2, k=2)  # Находим две лучших соответствия для каждой точки
```

- **`cv2.BFMatcher`**: Brute-Force Matcher — простой алгоритм для сопоставления описателей.
- **`knnMatch`**:
  - Для каждой точки на левом изображении находит `k=2` ближайших соответствий на правом изображении.
  - Это позволяет отфильтровать плохие соответствия позже.

---

#### 3. Фильтрация соответствий
```python
good_matches = [m for m, n in matches if m.distance < 0.7 * n.distance]  # Отфильтровываем плохие соответствия
```

- **Правило Лоу (Low's ratio test)**:
  - Если расстояние до лучшего соответствия (`m.distance`) меньше 0.7 расстояния до второго лучшего соответствия (`n.distance`), считаем это хорошим соответствием.
  - Это помогает исключить ошибочные соответствия.

---

#### 4. Проверка количества соответствий
```python
if len(good_matches) < 8:  # Проверяем, что есть достаточно хороших соответствий
    print("Недостаточно совпадений.")
    return None, None
```

- Для вычисления фундаментальной матрицы нужно минимум 8 хороших соответствий.
- Если их меньше, то процесс невозможен.

---

#### 5. Преобразование соответствий в координаты
```python
src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 2)  # Координаты точек на левом изображении
dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 2)  # Координаты точек на правом изображении
```

- **`kp1[m.queryIdx].pt`**: Получаем координаты соответствующей точки на левом изображении.
- **`kp2[m.trainIdx].pt`**: Получаем координаты соответствующей точки на правом изображении.
- Результаты преобразуются в массивы NumPy размером `(N, 2)`, где `N` — количество соответствий.

---

#### 6. Вычисление фундаментальной матрицы
```python
F, mask = cv2.findFundamentalMat(src_pts, dst_pts, cv2.FM_RANSAC)  # Вычисляем фундаментальную матрицу
if F is None:  # Проверяем, что фундаментальная матрица успешно вычислена
    print("Ошибка: не удалось вычислить фундаментальную матрицу.")
    return None, None
```

- **Фундаментальная матрица (`F`)**:
  - Описывает геометрические отношения между двумя изображениями.
  - Соотносит точки на одном изображении с точками на другом.
- **`cv2.FM_RANSAC`**: Метод RANSAC используется для исключения ошибочных соответствий.

---

#### 7. Вычисление гомографии
```python
H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC)  # Вычисляем гомографию
```

- **Гомография (`H`)**:
  - Матрица размером `3x3`, которая описывает преобразование между плоскостями.
  - В данном случае она используется для выравнивания одного из изображений относительно другого.

---

#### 8. Применение гомографии
```python
rectified_imgL = cv2.warpPerspective(imgL, H, (imgL.shape[1], imgL.shape[0]))  # Применяем гомографию к левому изображению
rectified_imgR = imgR  # Правому изображению не нужно применять преобразование
```

- **`cv2.warpPerspective`**: Применяет гомографию к изображению, изменяя его перспективу.
- Мы применяем гомографию только к левому изображению, так как правое остается без изменений.

---

#### 9. Возврат результатов
```python
return rectified_imgL, rectified_imgR  # Возвращаем откалиброванные изображения
```

- Функция возвращает два ректифицированных изображения: левое (`rectified_imgL`) и правое (`rectified_imgR`).

---

### Пример работы функции

Предположим, у нас есть два изображения:
- Левое изображение (`imgL`): Снято одной камерой.
- Правое изображение (`imgR`): Снято второй камерой.

Функция:
1. Находит ключевые точки и их описатели на обоих изображениях.
2. Сопоставляет эти точки.
3. Вычисляет фундаментальную матрицу.
4. Вычисляет гомографию.
5. Применяет гомографию к левому изображению, чтобы выровнять эпиполярные линии.

---

### Зачем это нужно?

Метод Хартли полезен в случаях, когда:
1. **Нет возможности провести калибровку камер**: Например, если камеры неизвестны или их параметры неизвестны.
2. **Требуется быстрая ректификация**: Этот метод проще и быстрее, чем классическая стереокалибровка.
3. **Сцена плоская**: Гомография работает лучше всего, когда наблюдаемая сцена является плоской или можно приблизительно считать плоской.
